{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aedbfde8-9053-494f-8a2c-f443c44e6ec8",
   "metadata": {},
   "source": [
    "# English to Portuguese Machine Translation with Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "20ee8c2b-fb89-4da2-9b15-7b80af343756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import tensorflow_text as tf_text\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee1a5d-a847-49db-af83-16cee5ff011d",
   "metadata": {},
   "source": [
    "# 1) Preprocessing sentences (Load, Vectorization, Train-Val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5a03c1f9-12bf-4463-ad0c-33e2d0800264",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = pathlib.Path(\"por-eng/por.txt\")\n",
    "\n",
    "def load_data(path):\n",
    "    text = path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split(\"\\t\") for line in lines]\n",
    "\n",
    "    context = np.array([context for target, context, _ in pairs])\n",
    "    target = np.array([target for target, context, _ in pairs])\n",
    "\n",
    "    return context, target\n",
    "\n",
    "\n",
    "portuguese_sentences, english_sentences = load_data(path_to_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f403c2b5-0dcf-445b-bd43-47ca9cf8f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(english_sentences)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(portuguese_sentences),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (english_sentences[is_train], portuguese_sentences[is_train]) \n",
    "    )\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "val_raw = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (english_sentences[~is_train], portuguese_sentences[~is_train])\n",
    "    )\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "15ba88f7-ef10-4c06-831e-038b978992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    text = tf_text.normalize_utf8(text, \"NFKD\")\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[^ a-z.?!,¿]\", \"\")\n",
    "    text = tf.strings.regex_replace(text, \"[.?!,¿]\", r\" \\0 \")\n",
    "    text = tf.strings.strip(text)\n",
    "    text = tf.strings.join([\"[SOS]\", text, \"[EOS]\"], separator=\" \")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c5dc1ea-1591-48f9-bf54-cf3548bd3c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 13:57:53.838359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [151967]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-28 13:57:53.838797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [151967]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-28 13:57:56.010854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [151967]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-28 13:57:56.011119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [151967]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_vocab_size = 12000\n",
    "\n",
    "english_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct, max_tokens=max_vocab_size, ragged=True\n",
    ")\n",
    "\n",
    "english_vectorizer.adapt(train_raw.map(lambda context, target: context))\n",
    "\n",
    "portuguese_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct, max_tokens=max_vocab_size, ragged=True\n",
    ")\n",
    "\n",
    "portuguese_vectorizer.adapt(train_raw.map(lambda context, target: target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c99b627d-66da-44e1-92c5-b14035bd9246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words of the english vocabulary:\n",
      "\n",
      "['', '[UNK]', '[SOS]', '[EOS]', '.', 'tom', 'i', 'to', 'you', 'the']\n",
      "\n",
      "First 10 words of the portuguese vocabulary:\n",
      "\n",
      "['', '[UNK]', '[SOS]', '[EOS]', '.', 'tom', 'que', 'o', 'nao', 'eu']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"First 10 words of the english vocabulary:\\n\\n{english_vectorizer.get_vocabulary()[:10]}\\n\")\n",
    "print(f\"First 10 words of the portuguese vocabulary:\\n\\n{portuguese_vectorizer.get_vocabulary()[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bf58c31f-281e-4ad7-9883-0d1f83b32663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese vocabulary is made up of 12000 words\n",
      "English vocabulary is made up of 12000 words\n"
     ]
    }
   ],
   "source": [
    "# Size of the vocabulary\n",
    "vocab_size_por = portuguese_vectorizer.vocabulary_size()\n",
    "vocab_size_eng = english_vectorizer.vocabulary_size()\n",
    "\n",
    "print(f\"Portuguese vocabulary is made up of {vocab_size_por} words\")\n",
    "print(f\"English vocabulary is made up of {vocab_size_eng} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f6e5b626-3f06-46ea-9579-0fed76050af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helps you convert from words to ids\n",
    "word_to_id = tf.keras.layers.StringLookup(\n",
    "    vocabulary=portuguese_vectorizer.get_vocabulary(), \n",
    "    mask_token=\"\", \n",
    "    oov_token=\"[UNK]\"\n",
    ")\n",
    "\n",
    "# This helps you convert from ids to words\n",
    "id_to_word = tf.keras.layers.StringLookup(\n",
    "    vocabulary=portuguese_vectorizer.get_vocabulary(),\n",
    "    mask_token=\"\",\n",
    "    oov_token=\"[UNK]\",\n",
    "    invert=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "105430fe-4427-48e4-9cef-63f109d8d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The id for the [UNK] token is 1\n",
      "The id for the [SOS] token is 2\n",
      "The id for the [EOS] token is 3\n",
      "The id for baunilha (vanilla) is 6276\n"
     ]
    }
   ],
   "source": [
    "unk_id = word_to_id(\"[UNK]\")\n",
    "sos_id = word_to_id(\"[SOS]\")\n",
    "eos_id = word_to_id(\"[EOS]\")\n",
    "baunilha_id = word_to_id(\"baunilha\")\n",
    "\n",
    "print(f\"The id for the [UNK] token is {unk_id}\")\n",
    "print(f\"The id for the [SOS] token is {sos_id}\")\n",
    "print(f\"The id for the [EOS] token is {eos_id}\")\n",
    "print(f\"The id for baunilha (vanilla) is {baunilha_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9cef4e59-ad3e-47b7-bc92-98a832f8f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "    context = english_vectorizer(context).to_tensor()\n",
    "    target = portuguese_vectorizer(target)\n",
    "    targ_in = target[:, :-1].to_tensor()\n",
    "    targ_out = target[:, 1:].to_tensor()\n",
    "    return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_data = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_data = val_raw.map(process_text, tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9aabee83-fa0f-455d-bfcb-59d4128f22bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 13:58:02.015265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype string\n",
      "\t [[{{node Placeholder/_13}}]]\n",
      "2024-07-28 13:58:02.015897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_18' with dtype int64\n",
      "\t [[{{node Placeholder/_18}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  2   9 219  30 576  11 115  23 946   4   3   0   0   0   0   0   0   0\n",
      "   0], shape=(19,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 38 229  71 156  28 890   4   3   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0], shape=(20,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[  2  38 229  71 156  28 890   4   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0], shape=(20,), dtype=int64)\n",
      "(64, 19)\n",
      "(64, 20)\n",
      "(64, 20)\n",
      "\n",
      "\n",
      "tf.Tensor(\n",
      "[   2   44  258   12 2405   96   11 3954    4    3    0    0    0    0\n",
      "    0    0    0    0], shape=(18,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[  12   56  194   15 6585   21   16 3131    4    3    0    0    0    0\n",
      "    0    0    0    0    0], shape=(19,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[   2   12   56  194   15 6585   21   16 3131    4    0    0    0    0\n",
      "    0    0    0    0    0], shape=(19,), dtype=int64)\n",
      "(64, 18)\n",
      "(64, 19)\n",
      "(64, 19)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (to_translate, sr_translation), translation in train_data.take(2):\n",
    "    print(to_translate[0])\n",
    "    print(translation[0])\n",
    "    print(sr_translation[0])\n",
    "    \n",
    "    print(to_translate.shape)\n",
    "    print(translation.shape)\n",
    "    print(sr_translation.shape)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2252f-46f5-43b2-9a92-e6a77b9704ea",
   "metadata": {},
   "source": [
    "# 2) Encoder, Self-attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "13033f02-31ef-4695-b660-628512e11d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 12000\n",
    "UNITS = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "07b4d32d-d3f5-4799-81f1-57dcb46321c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size , output_dim=units , mask_zero=True)  \n",
    "        self.rnn = tf.keras.layers.Bidirectional(merge_mode=\"sum\" , layer=tf.keras.layers.LSTM(units=units , return_sequences=True),)  \n",
    "\n",
    "\n",
    "    def call(self, context):\n",
    "        x = self.embedding(context)\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b8c48450-7c23-475a-a633-86af1ec9a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Encoder(tf.keras.layers.Layer):\n",
    "#     def __init__(self, vocab_size, units):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=units, mask_zero=True)\n",
    "#         self.rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True, return_state=True))\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = self.embedding(inputs)\n",
    "#         outputs, forward_h, forward_c, backward_h, backward_c = self.rnn(x)\n",
    "#         state_h = tf.concat([forward_h, backward_h], axis=-1)\n",
    "#         state_c = tf.concat([forward_c, backward_c], axis=-1)\n",
    "#         return outputs, state_h, state_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "82595711-ae63-43f8-90be-14694dd45952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, context, target):\n",
    "        attn_output = self.mha(query=target, value=context)\n",
    "        x = self.add([target, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "29be7094-0af3-478d-95d7-b0cbf0603d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of sentences in english has shape: (64, 18)\n",
      "\n",
      "Encoder output has shape: (64, 18, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of your class\n",
    "encoder = Encoder(VOCAB_SIZE, UNITS)\n",
    "\n",
    "# Pass a batch of sentences to translate from english to portuguese\n",
    "encoder_output = encoder(to_translate)\n",
    "\n",
    "print(f'Tensor of sentences in english has shape: {to_translate.shape}\\n')\n",
    "print(f'Encoder output has shape: {encoder_output.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9fd2f3a3-8b01-4be0-a575-f724ea7f78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of contexts has shape: (64, 18, 256)\n",
      "Tensor of translations has shape: (64, 19, 256)\n",
      "Tensor of attention scores has shape: (64, 19, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of your class\n",
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# The attention layer expects the embedded sr-translation and the context\n",
    "# The context (encoder_output) is already embedded so you need to do this for sr_translation:\n",
    "sr_translation_embed = tf.keras.layers.Embedding(VOCAB_SIZE, output_dim=UNITS, mask_zero=True)(sr_translation)\n",
    "\n",
    "# Compute the cross attention\n",
    "attention_result = attention_layer(encoder_output, sr_translation_embed)\n",
    "\n",
    "print(f'Tensor of contexts has shape: {encoder_output.shape}')\n",
    "print(f'Tensor of translations has shape: {sr_translation_embed.shape}')\n",
    "print(f'Tensor of attention scores has shape: {attention_result.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91dc88ca-2b75-4fd3-84d8-fed4330fba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoder_lstm = tf.keras.layers.LSTM(\n",
    "#     units=256,\n",
    "#     return_sequences=True,\n",
    "#     return_state=True\n",
    "# )\n",
    "\n",
    "# encoder_output_sequences, encoder_final_hidden_state, encoder_final_cell_state = encoder_lstm(encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d709f5-4f03-43a2-a196-49d57d036004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decoder_lstm = tf.keras.layers.LSTM(\n",
    "#     units=256,\n",
    "#     return_sequences=True,\n",
    "#     return_state=True\n",
    "# )\n",
    "\n",
    "# decoder_output_sequences, _, _ = decoder_lstm(decoder_inputs, initial_state=[encoder_final_hidden_state, encoder_final_cell_state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a9207d31-e35b-4ad0-aab1-e0de2289db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=units, mask_zero=True)\n",
    "        self.pre_attention_rnn = tf.keras.layers.LSTM(units=units, return_sequences=True, return_state=True)\n",
    "        self.attention = CrossAttention(units)\n",
    "        self.post_attention_rnn = tf.keras.layers.LSTM(units=units, return_sequences=True)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=vocab_size, activation=tf.nn.log_softmax)\n",
    "\n",
    "    def call(self, context, target, state=None, return_state=False):\n",
    "        x = self.embedding(target)\n",
    "        x, hidden_state, cell_state = self.pre_attention_rnn(x, initial_state=state)\n",
    "        x = self.attention(context, x)\n",
    "        x = self.post_attention_rnn(x)\n",
    "        logits = self.output_layer(x)\n",
    "        if return_state:\n",
    "            return logits, [hidden_state, cell_state]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70680597-cd5d-458f-bc46-0f70cf483762",
   "metadata": {},
   "source": [
    "# 3) Put together Encoder-Decoder into Translator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d5706c4b-254b-417c-9cfa-46d43128b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Translator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, units):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size, units)\n",
    "        self.decoder = Decoder(vocab_size, units)\n",
    "\n",
    "    def call(self, inputs): # inputs (tuple(tf.Tensor, tf.Tensor)): Tuple containing the context (sentence to translate) and the target (shifted-to-the-right translation)\n",
    "        \n",
    "        context, target = inputs\n",
    "        encoded_context = self.encoder(context)\n",
    "        \n",
    "        logits = self.decoder(encoded_context, target)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "76fc4e76-3085-40eb-b16f-fb72e0114c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of sentences to translate has shape: (64, 18)\n",
      "Tensor of right-shifted translations has shape: (64, 19)\n",
      "Tensor of logits has shape: (64, 19, 12000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of your class\n",
    "translator = Translator(VOCAB_SIZE, UNITS)\n",
    "\n",
    "# Compute the logits for every word in the vocabulary\n",
    "logits = translator((to_translate, sr_translation))\n",
    "\n",
    "print(f'Tensor of sentences to translate has shape: {to_translate.shape}')\n",
    "print(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\n",
    "print(f'Tensor of logits has shape: {logits.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf543e9-6a8a-487b-8d03-a0fca7d0c298",
   "metadata": {},
   "source": [
    "# 4) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3b968ad5-7d94-4a50-9ebe-9862a1df9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_loss(y_true, y_pred):\n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "    \n",
    "    # Check which elements of y_true are padding\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    \n",
    "    loss *= mask\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3bd3acf4-0c9b-482c-b563-7a30b5328c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8e4e07af-0f5b-4ddd-bd98-771dc52861c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_and_train(model, epochs=10, steps_per_epoch=500):\n",
    "    model.compile(optimizer=\"adam\", loss=masked_loss, metrics=[masked_acc, masked_loss])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data.repeat(),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=50,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)],\n",
    "    )\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bdfe16d0-2e60-4561-9f05-925026428dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 14:02:29.180519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_18' with dtype int64\n",
      "\t [[{{node Placeholder/_18}}]]\n",
      "2024-07-28 14:02:29.181058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_18' with dtype int64\n",
      "\t [[{{node Placeholder/_18}}]]\n",
      "2024-07-28 14:02:33.856005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-28 14:02:39.632970: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 4.5220 - masked_acc: 0.3021 - masked_loss: 4.5228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 14:07:17.917619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_14' with dtype int64\n",
      "\t [[{{node Placeholder/_14}}]]\n",
      "2024-07-28 14:07:17.918230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_14' with dtype int64\n",
      "\t [[{{node Placeholder/_14}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 302s 575ms/step - loss: 4.5220 - masked_acc: 0.3021 - masked_loss: 4.5228 - val_loss: 3.7680 - val_masked_acc: 0.3943 - val_masked_loss: 3.7685\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 282s 563ms/step - loss: 3.2777 - masked_acc: 0.4635 - masked_loss: 3.2780 - val_loss: 2.7389 - val_masked_acc: 0.5308 - val_masked_loss: 2.7404\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 367s 734ms/step - loss: 2.5094 - masked_acc: 0.5693 - masked_loss: 2.5108 - val_loss: 2.2205 - val_masked_acc: 0.6066 - val_masked_loss: 2.2225\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 286s 572ms/step - loss: 2.0935 - masked_acc: 0.6303 - masked_loss: 2.0944 - val_loss: 1.8792 - val_masked_acc: 0.6518 - val_masked_loss: 1.8799\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 260s 520ms/step - loss: 1.7909 - masked_acc: 0.6732 - masked_loss: 1.7921 - val_loss: 1.7095 - val_masked_acc: 0.6814 - val_masked_loss: 1.7124\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 341s 682ms/step - loss: 1.5480 - masked_acc: 0.7039 - masked_loss: 1.5491 - val_loss: 1.5283 - val_masked_acc: 0.7113 - val_masked_loss: 1.5297\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 282s 563ms/step - loss: 1.4267 - masked_acc: 0.7218 - masked_loss: 1.4277 - val_loss: 1.4336 - val_masked_acc: 0.7238 - val_masked_loss: 1.4347\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 303s 607ms/step - loss: 1.3603 - masked_acc: 0.7302 - masked_loss: 1.3612 - val_loss: 1.3687 - val_masked_acc: 0.7327 - val_masked_loss: 1.3691\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 274s 548ms/step - loss: 1.1540 - masked_acc: 0.7574 - masked_loss: 1.1545 - val_loss: 1.2050 - val_masked_acc: 0.7536 - val_masked_loss: 1.2064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_translator, history = compile_and_train(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7f553-7cc3-4706-8c59-d9394365d36a",
   "metadata": {},
   "source": [
    "# 5) Inference: Next token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3e4b6943-9d7d-40e4-9190-4fc1238acc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_next_token(decoder, context, next_token, done, state, temperature=0.0):\n",
    "    \n",
    "    \"\"\"Generates the next token in the sequence\n",
    "\n",
    "    Args:\n",
    "        decoder (Decoder): The decoder\n",
    "        context (tf.Tensor): Encoded sentence to translate\n",
    "        next_token (tf.Tensor): The predicted next token\n",
    "        done (bool): True if the translation is complete\n",
    "        state (list[tf.Tensor, tf.Tensor]): Hidden states of the pre-attention LSTM layer\n",
    "        temperature (float, optional): The temperature that controls the randomness of the predicted tokens. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple(tf.Tensor, np.float, list[tf.Tensor, tf.Tensor], bool): The next token, log prob of said token, hidden state of LSTM and if translation is done\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the logits and state from the decoder\n",
    "    logits, state = decoder(context, next_token, state=state, return_state=True)\n",
    "    \n",
    "    # Trim the intermediate dimension \n",
    "    logits = logits[:, -1, :]\n",
    "        \n",
    "    # If temp is 0 then next_token is the argmax of logits\n",
    "    if temperature == 0.0:\n",
    "        next_token = tf.argmax(logits, axis=-1)\n",
    "        \n",
    "    # If temp is not 0 then next_token is sampled out of logits\n",
    "    else:\n",
    "        logits = logits / temperature\n",
    "        next_token = tf.random.categorical(logits, num_samples=1)\n",
    "    \n",
    "    # Trim dimensions of size 1\n",
    "    logits = tf.squeeze(logits)\n",
    "    next_token = tf.squeeze(next_token)\n",
    "    \n",
    "    # Get the logit of the selected next_token\n",
    "    logit = logits[next_token].numpy()\n",
    "    \n",
    "    # Reshape to (1,1) since this is the expected shape for text encoded as TF tensors\n",
    "    next_token = tf.reshape(next_token, shape=(1,1))\n",
    "    \n",
    "    # If next_token is End-of-Sentence token you are done\n",
    "    if next_token == eos_id:\n",
    "        done = True\n",
    "    \n",
    "    return next_token, logit, state, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805fafa-2854-412e-9712-4bdb16cc7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder: The trained Decoder model that will generate predictions based on the input context and the current state.\n",
    "\n",
    "context: The encoded representation of the input sentence (from the encoder) that provides context for the decoder to generate the translation.\n",
    "\n",
    "next_token: The token predicted in the previous step. Initially, this could be a start-of-sequence token.\n",
    "\n",
    "done: A boolean flag indicating whether the translation is complete. It helps to stop the generation process when an end-of-sequence token is produced.\n",
    "\n",
    "state: The hidden states of the pre-attention LSTM layer in the decoder, which are updated at each step and used to maintain context.\n",
    "\n",
    "temperature: A parameter that controls the randomness of token generation. A temperature of 0.0 means always choosing the most likely token, while a higher temperature introduces more randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dde2b0b7-30fa-403d-ba68-db269aa86028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token: [[1367]]\n",
      "Logit: -18.7363\n",
      "Done? False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A sentence you wish to translate\n",
    "eng_sentence = \"Cat is the most adorable\"\n",
    "\n",
    "# Convert it to a tensor: tf.convert_to_tensor(eng_sentence) converts the sentence into a TensorFlow tensor. The [tf.newaxis] adds a new axis to the tensor, creating a batch dimension. \n",
    "# This is necessary because TensorFlow models expect input tensors to have a batch dimension.\n",
    "texts = tf.convert_to_tensor(eng_sentence)[tf.newaxis]\n",
    "\n",
    "# Vectorize it and pass it through the encoder\n",
    "context = english_vectorizer(texts).to_tensor()\n",
    "context = encoder(context)\n",
    "\n",
    "# SET STATE OF THE DECODER\n",
    "decoder_instance = Decoder(vocab_size=VOCAB_SIZE, units=UNITS)\n",
    "\n",
    "# There should be three initializer:\n",
    "# sos_id, hidden_state, cell_state. \n",
    "# Next token is Start-of-Sentence since you are starting fresh\n",
    "next_token = tf.fill((1,1), sos_id)\n",
    "\n",
    "# Hidden and Cell states of the LSTM can be mocked using uniform samples\n",
    "state = [tf.random.uniform((1, UNITS)), tf.random.uniform((1, UNITS))]\n",
    "\n",
    "# You are not done until next token is EOS token\n",
    "done = False\n",
    "\n",
    "# Generate next token\n",
    "next_token, logit, state, done = generate_next_token(decoder_instance , context, next_token, done, state, temperature=0.5)\n",
    "print(f\"Next token: {next_token}\\nLogit: {logit:.4f}\\nDone? {done}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c6bf9519-eb6b-4923-a982-c92605284e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7, 256), dtype=float32, numpy=\n",
       "array([[[-0.00096594,  0.00467819, -0.00716301, ...,  0.00231067,\n",
       "          0.00938596,  0.00606533],\n",
       "        [-0.0054131 ,  0.00656668, -0.00177414, ...,  0.00797553,\n",
       "         -0.00529242,  0.00201095],\n",
       "        [ 0.00638044,  0.01237875, -0.00468413, ...,  0.01869044,\n",
       "         -0.01541931,  0.00767817],\n",
       "        ...,\n",
       "        [-0.00122468,  0.02203771, -0.00367437, ...,  0.01645075,\n",
       "         -0.00977448,  0.00972566],\n",
       "        [-0.0032827 ,  0.02007942, -0.01447834, ...,  0.00954908,\n",
       "         -0.0106133 , -0.00388205],\n",
       "        [-0.00512495,  0.01496253, -0.01858178, ...,  0.00752145,\n",
       "         -0.00435399, -0.00835634]]], dtype=float32)>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "afe079de-37ca-49d1-914b-9355ba2ccd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'publico']], dtype=object)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word(next_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f455a2-0d01-4b1b-878e-108f5d1f1697",
   "metadata": {},
   "source": [
    "# 6) Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d969ce-d1bb-46a4-8c5e-fc3810881ea9",
   "metadata": {},
   "source": [
    "Now you can combine all the steps to translate a given sentence. To do this, we generate translate function provided below. This function will handle the following steps:              \n",
    "\n",
    "1. Process and encode the sentence to be translated.            \n",
    "2. Initialize the decoder's initial state.          \n",
    "3. Predict the next token (starting with the `<SOS>` token) for a maximum number of iterations (in case the `<EOS>` token is never returned).           \n",
    "4. Return the translated text (as a string), the logit of the last iteration (which helps measure the certainty of the complete sequence translation), and the translation in token format.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "28ae608e-5c25-4838-92d5-27e7becc3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens, id_to_word):\n",
    "    words = id_to_word(tokens)\n",
    "    result = tf.strings.reduce_join(words, axis=-1, separator=\" \")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f9c5b4db-4cbf-437b-ab6f-cb5006cdce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate(model, text, max_length=50, temperature=0.0):\n",
    "    \"\"\"Translate a given sentence from English to Portuguese\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained translator\n",
    "        text (string): The sentence to translate\n",
    "        max_length (int, optional): The maximum length of the translation. Defaults to 50.\n",
    "        temperature (float, optional): The temperature that controls the randomness of the predicted tokens. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple(str, np.float, tf.Tensor): The translation, logit that predicted <EOS> token and the tokenized translation\n",
    "    \"\"\"\n",
    "    # Lists to save tokens and logits\n",
    "    tokens, logits = [], []\n",
    "\n",
    "    # PROCESS THE SENTENCE TO TRANSLATE\n",
    "    \n",
    "    # Convert the original string into a tensor\n",
    "    text_tensor = tf.convert_to_tensor([text])\n",
    "    \n",
    "    # Vectorize the text using the correct vectorizer\n",
    "    context = english_vectorizer(text_tensor).to_tensor()\n",
    "    \n",
    "    # Get the encoded context (pass the context through the encoder)\n",
    "    context = model.encoder(context)\n",
    "    \n",
    "    # INITIAL STATE OF THE DECODER\n",
    "    \n",
    "    # First token should be SOS token with shape (1,1)\n",
    "    next_token = tf.fill((1, 1), sos_id)\n",
    "    \n",
    "    # Initial hidden and cell states should be tensors of zeros with shape (1, UNITS)\n",
    "    state = [tf.zeros((1, UNITS)), tf.zeros((1, UNITS))]\n",
    "    \n",
    "    # You are done when you draw a EOS token as next token (initial state is False)\n",
    "    done = False\n",
    "\n",
    "    # Iterate for max_length iterations\n",
    "    for _ in range(max_length):\n",
    "        # Generate the next token\n",
    "        try:\n",
    "            next_token, logit, state, done = generate_next_token(\n",
    "                decoder=model.decoder,\n",
    "                context=context,\n",
    "                next_token=next_token,\n",
    "                done=done,\n",
    "                state=state,\n",
    "                temperature=temperature\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Problem generating the next token: {e}\")\n",
    "        \n",
    "        # If done then break out of the loop\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        # Add next_token to the list of tokens\n",
    "        tokens.append(next_token)\n",
    "        \n",
    "        # Add logit to the list of logits\n",
    "        logits.append(logit)\n",
    "   \n",
    "    # Concatenate all tokens into a tensor\n",
    "    tokens = tf.concat(tokens, axis=-1)\n",
    "    \n",
    "    # Convert the translated tokens into text\n",
    "    translation = tf.squeeze(tokens_to_text(tokens, id_to_word))\n",
    "    translation = translation.numpy().decode()\n",
    "    \n",
    "    return translation, logits[-1], tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d577dad3-02a9-4b24-adaf-d6efe2286a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0.0\n",
      "\n",
      "Original sentence: Cats are the most lovely animals\n",
      "Translation: os gatos sao os animais mais [UNK] .\n",
      "Translation tokens:[[ 40 758  73  40 938  32   1   4]]\n",
      "Logit: -1.978\n"
     ]
    }
   ],
   "source": [
    "# Running this cell multiple times should return the same output since temp is 0\n",
    "\n",
    "temp = 0.0 \n",
    "original_sentence = \"Cats are the most lovely animals\"\n",
    "\n",
    "translation, logit, tokens = translate(trained_translator, original_sentence, temperature=temp)\n",
    "\n",
    "print(f\"Temperature: {temp}\\n\\nOriginal sentence: {original_sentence}\\nTranslation: {translation}\\nTranslation tokens:{tokens}\\nLogit: {logit:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b806ad-7f80-4fe1-91bb-b15ec08da815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f25cf-5147-4334-9150-a40bda733272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
